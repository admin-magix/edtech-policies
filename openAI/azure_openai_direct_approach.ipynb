{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elena\\articles_gpt\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "from openai.types.chat.completion_create_params import ResponseFormat\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import openai \n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = #azure openai api key\n",
    "azure_endpoint = # azure endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    api_key=api_key,\n",
    "    api_version=\"2024-03-01-preview\",\n",
    "    azure_endpoint=azure_endpoint\n",
    ")\n",
    "deployment_gpt_name = # deployment name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('abstract_policies.json', 'r', encoding='utf=8') as file:\n",
    "    abstracts_json = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('search_data_simple_GDPR.txt', 'r') as file:\n",
    "    codes_questions = file.readlines()\n",
    "\n",
    "codes_questions\n",
    "questions = [item.strip('\\n\\t') for item in codes_questions]\n",
    "questions\n",
    "list_questions = {}\n",
    " \n",
    "for quest in range(0, len(questions), 2):\n",
    "    code = questions[quest].strip(':')\n",
    "    question = questions[quest+1]\n",
    "    list_questions[code] = question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_response_trial(policy_id, response, file_path):\n",
    "    response_content = response.choices[0].message.content if response.choices else \"No response from the API\"\n",
    "    with open(file_path, \"r\") as file:\n",
    "        existing_data = json.load(file)\n",
    "    \n",
    "    existing_data[policy_id] = response_content\n",
    "\n",
    "    with open(file_path, \"w\") as file:\n",
    "        json.dump(existing_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_format(questions_dict):\n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": \"\"\" You are an auditor that needs to review multiple privacy policies, each one identified with a `PolicyID`.\n",
    "    For each policy, I am going to provide you the `PolicyID` and `PolicyText`. For each policy, answer each question that I give you with a \"Yes\"/\"No\" answer and if the answer is \"Yes\" then provide an extract from the policy that is LONGER than 200 characters and best fits the answer, otherwise return an empty string, nothing else that differs from this.\n",
    "    Make sure that your response is only in a JSON format like this and DO NOT PROVIDE ANY ADDITIONAL TEXT: `{'QuestionID': {\"Answer\": \"Your answer\", \"Extract\": \"Extract from the policy\"}}`, where \" Your Answer\" represents your answer to the question, \"Extract from the policy\" is the best fit extract and 'QuestionID' is the id of the question that I provide you with.\n",
    "    Below is the list of questions, in the following format `{'QuestionID':'QuestionText'}`:\"\"\"+ f\"{questions_dict}\" }\n",
    "]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_by_policy_id(data, policy_id):\n",
    "    if len(data) > 0:\n",
    "        for response in data[\"responses\"]:\n",
    "            if response[\"PolicyID\"] == policy_id:\n",
    "                return response[\"Response\"]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_cached_questions(cached_questions, original_questions):\n",
    "    missing = {}\n",
    "    for key, value in original_questions.items():\n",
    "        if cached_questions:\n",
    "            if key not in cached_questions.keys():\n",
    "                missing[key] = value \n",
    "        else:\n",
    "            return original_questions\n",
    "\n",
    "    return missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change number of questions and policies as needed\n",
    "questions_for_answering = dict(list(list_questions.items()))\n",
    "test_policies = {}\n",
    "\n",
    "for key, value in list(abstracts_json.items()):\n",
    "    test_policies[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = {}\n",
    "file_path = '' # save responses to a file\n",
    "answered_policies_ids = []\n",
    "with open(file_path, \"r\") as file:\n",
    "    response_data = json.load(file)\n",
    "if len(response_data) > 0:\n",
    "    for policy in response_data['responses']:\n",
    "        answered_policies_ids.append(policy['PolicyID'])\n",
    "\n",
    "def add_message(role, content, message_format):\n",
    "    message_format.append( {\"role\": role, \"content\": content})\n",
    "\n",
    "\n",
    "\n",
    "def handle_conversation():\n",
    "    for policy_id, policy in test_policies.items():\n",
    "        prompt = \"{'PolicyID':'\"+f\"{policy_id}\"+\"', 'PolicyText':'\"+ policy +\"'}.\"\n",
    "        cached_answers = get_response_by_policy_id(response_data, policy_id)\n",
    "        missing_questions = get_non_cached_questions(cached_answers, questions_for_answering)\n",
    "\n",
    "        if len(missing_questions) > 0:\n",
    "    \n",
    "            message_format = prompt_format(missing_questions)\n",
    "            add_message(\"user\", prompt, message_format)\n",
    "\n",
    "            messages_for_api = [{\"role\": m[\"role\"], \"content\": m[\"content\"]} for m in message_format]\n",
    "\n",
    "            message_format.remove({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "            response = client.chat.completions.create(\n",
    "                model=deployment_gpt_name,\n",
    "                messages=messages_for_api\n",
    "            )\n",
    "            \n",
    "            responses[policy_id] = response\n",
    "\n",
    "            if response.choices and len(response.choices) > 0:\n",
    "                full_response = response.choices[0].message.content\n",
    "                save_response_trial(policy_id, response, file_path)\n",
    "                response = None\n",
    "            else:\n",
    "                print(\"No response from the API\")\n",
    "handle_conversation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
